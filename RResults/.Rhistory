d3 = simdata(3)
d4 = simdata(5)
d5 = simdata(10)
```
Now that I have the data, I can fit a GLM to each dataset (using the built-in R function).
```{r}
m1 = glm(y~x, data = d1, family = "gaussian")
m2 = glm(y~x, data = d2, family = "gaussian")
m3 = glm(y~x, data = d3, family = "gaussian")
m4 = glm(y~x, data = d4, family = "gaussian")
m5 = glm(y~x, data = d5, family = "gaussian")
```
For each dataset, I'll also calculate the loglikelihood for $- 10 \le b \le 10$ to create a probability density plot. Again, I'll start by creating a function that does it for me.
```{r}
densityplot = function(data, sigma){
# start by creating a list of b values
b = seq(-10, 10, .01)
# then create an array to hold the results
res = rep(0, length(b))
# loop through values of b from -10 to 10 and calculate the likelihood of the data
for(i in 1:length(b)){
# calculate the error based for this value of b
error = data$y - (3-b[i]*data$x)
# get the loglikelihood of the error based on the normal distribution it was drawn from
density = dnorm(x=error, mean=0, sd=sigma, log=T)
# add all the data points together and add them to the array
res[i] = sum(density)
}
# at the end, return the results
return(res)
}
```
Now I'll get the likelihood curve for each dataset and plot them all.
```{r}
# run the funciton to get the data
p1 = densityplot(d1, .5)
p2 = densityplot(d2, 1)
p3 = densityplot(d3, 3)
p4 = densityplot(d4, 5)
p5 = densityplot(d5, 10)
# get some colors
r = rainbow(5)
# now I can use them to plot
plot(x=seq(-10,10,.01), y=p1, type="l", col=r[1], xlab="Value of b", ylab="LogLikelihood")
lines(x=seq(-10,10,.01), y=p2, col=r[2])
lines(x=seq(-10,10,.01), y=p3, col=r[3])
lines(x=seq(-10,10,.01), y=p4, col=r[4])
lines(x=seq(-10,10,.01), y=p5, col=r[5])
legend(4.5, y = -7000000, legend = c("sigma = .5", "sigma = 1", "sigma = 3", "sigma = 5", "sigma = 10"), lty = 1, col = r)
```
The curve for $\sigma = .5$ is the most "peaky" because it has the least error or deviation from the mean, which makes it more obvious what the true parameter values are. As $\sigma$ increases, the relationship between x and y becomes less clear, so, just based on the data, it becomes equally likely for the parameters to have any of a range of values, even though the standard deviation of the error is known.
knitr::opts_chunk$set(echo = TRUE)
m1
install.packages("coin")
iris
head(iris)
plot(iris$Petal.Length~iris$Petal.Length+iris$Species)
plot(iris$Petal.Length~iris$Petal.Width+iris$Species)
plot(iris$Petal.Length~iris$Petal.Width*iris$Species)
plot(iris$Petal.Length~iris$Petal.Width, col=Species)
plot(iris$Petal.Length~iris$Petal.Width, col=iris$Species)
lm(iris$Petal.Length~iris$Petal.Width*iris$Species)
m1 = lm(iris$Petal.Length~iris$Petal.Width*iris$Species)
summary(m1)
m2 = lm(iris$Petal.Length~iris$Petal.Width+iris$Species)
summary(m2)
points(iris$Petal.Width, predict(m1), col = iris$Species)
points(iris$Petal.Width, predict(m1), col = iris$Species, type = "l")
points(iris$Petal.Width, predict(m1), col = iris$Species, pch = 16, type = "l")
points(iris$Petal.Width, predict(m1), col = iris$Species, pch = 16)
points(iris$Petal.Width, predict(m1), col = iris$Species, pch = 16)
plot(iris$Petal.Length~iris$Petal.Width, col=iris$Species)
points(iris$Petal.Width, predict(m1), col = iris$Species, pch = 16)
points(iris$Petal.Width, predict(m2), col = iris$Species, pch = 16)
plot(iris$Petal.Length~iris$Petal.Width, col=iris$Species)
points(iris$Petal.Width, predict(m2), col = iris$Species, pch = 16)
plot(iris$Petal.Length~iris$Petal.Width, col=iris$Species)
points(iris$Petal.Width, predict(m1), col = iris$Species, pch = 16)
m3 = lm(iris$Petal.Length~iris$Petal.Width:iris$Species)
summary(m3)
plot(iris$Petal.Length~iris$Petal.Width, col=iris$Species)
points(iris$Petal.Width, predict(m3), col = iris$Species, pch = 16)
install.packages("lme4")
install.packages("lmerTest")
dat <- read.csv("Horseshoe crab.csv", header=T)
hist(dat$Sa)#not really adapted to count data. Why?
barplot(table(dat$Sa))#better but where is the gap between 10 and 14?
dat$SaCat <- factor(dat$Sa, levels=0:14)
barplot(table(dat$SaCat))#nice!
barplot(table(dat$SaCat), main="Distribution of the number of satellite males",
col="cadetblue3", las=1, xlab="# satellite males", ylab="Frequency")#nice!
#relationship between female carapace width and Sa:
plot(Sa~W, data=dat)#weird renge for the x-axis
dat[order(dat$W),]#lots of NA in the Sa column. Let's get rid of these rows
dat <- dat[!is.na(dat$Sa),]#exclamation mark stands for "NOT"
plot(Sa~W, data=dat)#better
model1 <- glm(Sa~W, data=dat, family=poisson)
summary(model1)
library(lme4)
library(lmerTest)
model2 <- lmer(y ~ sex + (1|location))
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model1, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
barplot(table(dat$SaCat), main="Distribution of the number of satellite males",
col="cadetblue3", las=1, xlab="# satellite males", ylab="Frequency")#nice!
dat[order(dat$W),]#lots of NA in the Sa column. Let's get rid of these rows
dat <- dat[!is.na(dat$Sa),]#exclamation mark stands for "NOT"
plot(Sa~W, data=dat)#better
dat <- read.csv("Horseshoe crab.csv", header=T)
View(dat)
dat[order(dat$W),]#lots of NA in the Sa column. Let's get rid of these rows
dat <- dat[!is.na(dat$Sa),]#exclamation mark stands for "NOT"
plot(Sa~W, data=dat)#better
model2 <- glm(Sa~W, data=dat, family=quasipoisson)
summary(model2)
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model2, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
dat <- read.csv("Horseshoe crab.csv", header=T)
model2 <- glm(Sa~W, data=dat, family=quasipoisson)
summary(model2)
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model2, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
dat <- dat[!is.na(dat$Sa),]#exclamation mark stands for "NOT"
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model2, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
predict(model2, type="response",
newdata=list(W=seq(21, 32, 0.1)))
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model2, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
summary(model2)
model1 <- glm(Sa~W, data=dat, family=poisson)
summary(model1)
plot(Sa~W, data=dat)
points(seq(21, 32, 0.1), predict(model1, type="response",
newdata=list(W=seq(21, 32, 0.1))),
type="l", lty=2, col="red")
model2 <- glm(Sa~W, data=dat, family=quasipoisson)
summary(model2)
location <- rep(LETTERS[1:20], each=50)
location <- factor(location)
meanLength <- rep(rnorm(20, 0, sd=5), each=50)
sex <- factor(rep(rep(c("M", "F"), each=25), 20))
sexEffect <- ifelse(sex=="M", -1.5, 1.5)##deviations from population average
y <- 20+sexEffect+meanLength+rnorm(20*50, 0, 1)
plot(as.numeric(location), y, col=sex)##not so great
plot(as.numeric(location)+0.1*sexEffect, y, col=sex, xlab="location"); segments(1:20, 12,
1:20, 35, lty=2, col="grey")##better
model1 <- glm(y~sex+location)
summary(model1)
library(lme4)
library(lmerTest)
model2 <- lmer(y ~ sex + (1|location))
#the intercept(symbol:"1") is assumed to vary randomly among locations following
#a normal distribution
summary(model2)
model2bis <- lmer(y ~ sex + (1|location), REML = F)
ranova(model2bis)
location <- rep(LETTERS[1:20], each=50)
location <- factor(location)
meanLength <- rep(rnorm(20, 0, sd=5), each=50)
sex <- factor(rep(rep(c("M", "F"), each=25), 20))
sexEffect <- ifelse(sex=="M", -1.5, 1.5)##deviations from population average
y <- 20+sexEffect+meanLength+rnorm(20*50, 0, 1)
plot(as.numeric(location), y, col=sex)##not so great
plot(as.numeric(location)+0.1*sexEffect, y, col=sex, xlab="location"); segments(1:20, 12,
1:20, 35, lty=2, col="grey")##better
plot(as.numeric(location), y, col=sex)##not so great
plot(as.numeric(location)+0.1*sexEffect, y, col=sex, xlab="location"); segments(1:20, 12,
1:20, 35, lty=2, col="grey")##better
model1 <- glm(y~sex+location)
summary(model1)
model2 <- lmer(y ~ sex + (1|location))
#the intercept(symbol:"1") is assumed to vary randomly among locations following
#a normal distribution
summary(model2)
model2bis <- lmer(y ~ sex + (1|location), REML = F)
ranova(model2bis)
# mathematical simulation for the alarm model
# start with a functions for the learning model (at equilibrium)
indalarm = function(a, p, d){
return(a*p*d)
}
indnoalarm = function(a, p, d){
return((1-a)*p*d)
}
socalarm = function(a, p, d, s){
return(a*p*d*(1+p*(1-d)*(1-s)*a)/(1-p*(1-d)*a*s))
}
socnoalarm = function(a, p, d, s){
return((1-a)*p*d*(1+(1-p+p*(1-d)*(1-a))*(1-s))/(1-(1-p+p*(1-d)*(1-a))*s))
}
# and now I can use those in the evolution model
# I'm going to start by calculating the relative fitness of each strategy, though there should be some way to solve for s
fitness = function(a, p, d, b, c, s = NULL){
# if there proprotion of social learners is included, get their learning withand without alarm
if(!is.null(s)){
alarm = socalarm(a, p, d, s)
noalarm = socnoalarm(a, p, d, s)
} else {
# otherwise get individual learning
alarm = indalarm(a, p, d)
noalarm = indalarm(a, p, d)
}
# and then use that to calculate the fitness
return(a*p*(1-alarm)*(b-c)+((1-a)*p*(b-c)+(1-p)*b)*(1-noalarm))
}
# now I'm going to initialize a dataframe with all the parameter values, which will hold the results
results = data.frame(a=double(), p=double(), d=double(), s=double(), b=double(), c=double(), indv=double(),
ialarm=double(), inoalarm=double(), socv=double(), salarm=double(), snoalarm=double())
# loop through a bunch of parameter values and get the results
for(a in seq(0, 1, .01)){
for(p in seq(0, 1, .01)){
for(d in seq(0, 1, .01)){
for(s in seq(0, 1, .01)){
for(b in 0:10){
for(c in 0:10){
results[nrow(results)+1, ] = c(a,p,d,s,b,c,fitness(a,p,d,b,c),indalarm(a,p,d),indnoalarm(a,p,d),
fitness(a,p,d,b,c,s=s),socalarm(a,p,d,s),socnoalarm(a,p,d,s))
}
}
}
}
}
}
# now I'm going to initialize a dataframe with all the parameter values, which will hold the results
results = data.frame(a=double(), p=double(), d=double(), s=double(), b=double(), c=double(), indv=double(),
ialarm=double(), inoalarm=double(), socv=double(), salarm=double(), snoalarm=double())
# loop through a bunch of parameter values and get the results
for(a in seq(0, 1, .1)){
for(p in seq(0, 1, .1)){
for(d in seq(0, 1, .1)){
for(s in seq(0, 1, .1)){
for(b in 0:10){
for(c in 0:10){
results[nrow(results)+1, ] = c(a,p,d,s,b,c,fitness(a,p,d,b,c),indalarm(a,p,d),indnoalarm(a,p,d),
fitness(a,p,d,b,c,s=s),socalarm(a,p,d,s),socnoalarm(a,p,d,s))
}
}
}
}
}
}
# now I'm going to initialize a dataframe with all the parameter values, which will hold the results
results = data.frame(a=double(), p=double(), d=double(), s=double(), b=double(), c=double(), indv=double(),
ialarm=double(), inoalarm=double(), socv=double(), salarm=double(), snoalarm=double())
# loop through a bunch of parameter values and get the results
for(a in seq(0, 1, .2)){
for(p in seq(0, 1, .2)){
for(d in seq(0, 1, .2)){
for(s in seq(0, 1, .2)){
for(b in seq(0, 10, 2)){
for(c in seq(0, 10, 2)){
results[nrow(results)+1, ] = c(a,p,d,s,b,c,fitness(a,p,d,b,c),indalarm(a,p,d),indnoalarm(a,p,d),
fitness(a,p,d,b,c,s=s),socalarm(a,p,d,s),socnoalarm(a,p,d,s))
}
}
}
}
}
}
View(results)
# replace NaNs with 0
results[is.na(results)] = 0
View(results)
library(ggplot2)
library(tidyr)
library(dplyr)
testparams = c("a", "p", "d", "s", "b", "c")
for(param in testparams){
plot = ggplot(d4, aes(x = results[, p], y = socv)) + geom_line() + xlab(p)
ggsave(paste(param, ".png"))
}
testparams = c("a", "p", "d", "s", "b", "c")
for(param in testparams){
plot = ggplot(results, aes(x = results[, param], y = socv)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
setwd("Documents/Research/IMCapstone/RResults")
getwd()
plotr = gather(results, type, value, c("socv", "indv"))
View(plotr)
for(param in testparams){
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(results, aes(x = results[, param], y = value, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
for(param in testparams){
plotr$param = pltr[,param]
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(results, aes(x = results[, param], y = value, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
for(param in testparams){
plotr$param = plotr[,param]
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(results, aes(x = results[, param], y = value, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
View(plotr)
testparams = c("a", "p", "d", "s", "b", "c")
plotr = gather(results, type, value, c("socv", "indv"))
for(param in testparams){
plotr$param = plotr[,param]
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(results, aes(x = results[, param], y = value, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
View(pltr)
View(plotr)
for(param in testparams){
plotr$param = plotr[,param]
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(results, aes(x = results[, param], y = mean, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
for(param in testparams){
plotr$param = plotr[,param]
pltr = summarize(group_by(plotr, param, type), N = length(value), mean = mean(value, na.rm = T),
sd = sd(value, na.rm = T), se = sd / sqrt(N))
plot = ggplot(pltr, aes(x = param, y = mean, color = type)) + geom_line() + xlab(param)
ggsave(paste(param, ".png"))
}
results$socprop = results$socv/(results$socv + results$indv)
for(p1 in testparams){
for(p2 in testparams){
if(p1 != p2){
plotResults(results, c(p1, p2), paste(p1, p2), list(c("socprop")), c("Relative Fitness of Social Learners"), catlabels = p2)
}
}
}
library(ggplot2)
library(tidyr)
library(dplyr)
library(gridExtra)
# generates line graphs or bar plots (as applicable) of the results provided based on:
# dtable - data frame of results, with columns for each parameter to split/graph by, and each category of results
# params - vector of column names to split/graph:
#   the lines/bars will be colored based on the last column listed
#   the x-axis will be based on the second to last column listed
#   the data will be split into graphs based on all the other columns (it will create one graph for each combination of values)
# fname - the beginning of the name of all the outputted files
#   it will add on all the names of the parameters split by and their values for each graph
# testvars - list of vectors of column names to plot together (y values) on the same graph
#   can be used to color the graph or for the x-axis if included in params as "category"
# testlabels - vector of labels for the y-axis of each graph, should be the same length as testvars
# catlabels - vector of labels for the colors of each graph, should be the same length as testvars
plotResults = function(dtable, params, fname, testvars, testlabels, catlabels, scatter = F,
linelabels = c(), shapelabels = c(), savelv = 2){
if(length(params) == savelv){
# loop through each set of measures to crete the corresponding plots
for(v in 1:length(testvars)) {
# format the data for ggplot
plotd = gather(dtable, category, measure, testvars[[v]])
# make sure nothing is infinite
is.na(plotd) = sapply(plotd, is.infinite)
# grab the x axis variable for convenience
plotd$x = plotd[, params[length(params)-1]]
# split the category to see if there are actually multiple
cats = strsplit(params[length(params)], " ")[[1]]
# the category can be split by color
plotd$c = ""
# by shape
plotd$s = ""
# and by linetype
plotd$l = ""
# I'm going to have an index here to increment
j = 1
# if the data is going to be split into shapes, use the first category for that
if(length(shapelabels) > 0){
plotd$s = factor(plotd[, cats[1]])
j = j+1
# also, if there's only one shape label given use that
if(length(shapelabels) == 1){
slab = shapelabels[1]
} else {
# otherwise, use the label corresponding to this test variable
slab = shapelabels[v]
}
} else {
slab = ""
}
# if there are more categories left and this is going to be split into linetypes, do so
if(length(cats) >= j & length(linelabels) > 0){
plotd$l = factor(plotd[, cats[j]])
j = j+1
# also set the line label
if(length(linelabels) == 1){
llab = linelabels[1]
} else {
llab = linelables[v]
}
} else {
llab = ""
}
# if there are more categories left, combine them for use as the color
if(length(cats) >= j) {
for(i in j:length(cats)){
plotd$c = paste(plotd$c, plotd[, cats[i]])
}
# also set the color label
if(length(catlabels) == 1){
clab = catlabels[1]
} else {
clab = catlables[v]
}
} else {
clab = ""
}
# turn the color into a factor
plotd$c = factor(plotd$c)
# if this isn't a scatter plot average the relevant measures so there aren't duplicates
if(!scatter){
plotd = summarize(group_by(group_by_at(plotd, params[1:(length(params)-2)]), x, c, s, l, add = T),
N = length(measure), mean = mean(measure, na.rm = T),
sd = sd(measure, na.rm = T), se = sd / sqrt(N))
plotd = as.data.frame(plotd)
}
# plot the results
# create a scatter plot if scatter is true
if(scatter){
plot = ggplot(plotd, aes(x = x, y = measure, colour = c)) + geom_point(aes(shape = s)) +
ylab(testlabels[v]) + xlab(params[length(params)-1]) + labs(colour = params[length(params)]) +
guides(colour=guide_legend(title=clab), shape=guide_legend(title=slab)) +
geom_smooth(method = 'lm', se = F)
} else if(is.numeric(plotd$x)){
# otherwise, if the x-axis is numeric, turn this into a linegraph
plot = ggplot(plotd, aes(x = x, y = mean, colour = c)) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1) + geom_line(aes(linetype = l)) +
geom_point(aes(shape = s)) + ylab(testlabels[v]) + xlab(params[length(params)-1]) +
labs(colour = params[length(params)]) +
guides(colour=guide_legend(title=clab), shape=guide_legend(title=slab), linetype=guide_legend(title = llab))
} else {
# otherwise, turn it into a bargraph
plot = ggplot(plotd, aes(x = x, y = mean, fill = c)) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.2, position=position_dodge(.9)) +
geom_bar(stat = "identity", position = "dodge") + ylab(testlabels[v]) + xlab(params[length(params)-1]) +
labs(fill = params[length(params)]) + guides(fill=guide_legend(title=clab))
}
# if the save level is higher than 2, make a grid of grids for all the remaining parameters
# if the save level is 3, just make a single row
if(savelv == 3){
plot = plot + facet_grid(cols = vars(plotd[, params[(length(params)-2)]]))
} else if (savelv > 3) {
# otherwise, make a grid from the last two parameters
plot = plot + facet_grid(rows = vars(plotd[, params[(length(params)-2)]]),
cols = vars(plotd[, params[(length(params)-3)]]))
}
ggsave(paste(fname, testlabels[v], ".png", sep = ""), plot = plot)
}
} else {
# otherwise, recurse on all values of this parameter
for(v in unique(dtable[, params[1]])){
# update the filename to pass it
f = paste(fname, params[1], v, sep = "")
# get the corresponding plot/grid of plots
plotResults(dtable[dtable[, params[1]] == v, ], params[-1], f, testvars, testlabels, catlabels,
scatter, linelabels = linelabels, shapelabels = shapelabels, savelv = savelv)
}
}
}
results$socprop = results$socv/(results$socv + results$indv)
for(p1 in testparams){
for(p2 in testparams){
if(p1 != p2){
plotResults(results, c(p1, p2), paste(p1, p2), list(c("socprop")), c("Relative Fitness of Social Learners"), catlabels = p2)
}
}
}
View(results)
res$alarm = results$a
res$predator = results$p
res$detection = results$d
res$social = results$s
res$benefit = results$b
res$cost = results$c
res$socprop = results$socv/(results$socv + results$indv)
res = data.frame()
res$alarm = results$a
res$predator = results$p
res$detection = results$d
res$social = results$s
res$benefit = results$b
res$cost = results$c
res$socprop = results$socv/(results$socv + results$indv)
res = data.frame(alarm = results$a, predator = results$p, detection = results$d, social = results$s,
benefit = results$b, cost = results$c, socprop = results$socv/(results$socv + results$indv))
res = data.frame(alarm = results$a, predator = results$p, detection = results$d, social = results$s,
benefit = results$b, cost = results$c, socprop = results$socv/(results$socv + results$indv))
testparams = c("alarm", "predator", "detection", "social", "benefit", "cost")
for(p1 in testparams){
for(p2 in testparams){
if(p1 != p2){
plotResults(res, c(p1, p2), paste(p1, p2), list(c("socprop")), c("Relative Fitness of Social Learners"), catlabels = p2)
}
}
}
write.csv(results, "mathSimResults.csv")
